{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import lib_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_sqlobject = sqlite3.connect('amazon-fine-food-reviews/database.sqlite') \n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT Id, Score, Text FROM Reviews WHERE Id > 500000 \"\"\", connection_sqlobject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500001</td>\n",
       "      <td>5</td>\n",
       "      <td>I was looking for an easy and convenient way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500002</td>\n",
       "      <td>5</td>\n",
       "      <td>DO NOT be freaked out by the ostrich! This tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500003</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought the Ostrim with a little apprehension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500004</td>\n",
       "      <td>5</td>\n",
       "      <td>At only 80 calories these are a great bang for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500005</td>\n",
       "      <td>5</td>\n",
       "      <td>These are quite tasty and by far the leanest, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Text\n",
       "0  500001      5  I was looking for an easy and convenient way t...\n",
       "1  500002      5  DO NOT be freaked out by the ostrich! This tas...\n",
       "2  500003      5  I bought the Ostrim with a little apprehension...\n",
       "3  500004      5  At only 80 calories these are a great bang for...\n",
       "4  500005      5  These are quite tasty and by far the leanest, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(filtered_data))\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5981\n",
      "3509\n",
      "5031\n",
      "9611\n",
      "44322\n"
     ]
    }
   ],
   "source": [
    "categories = ['1','2','3','4','5']\n",
    "cat_tweets=[[],[],[],[],[]]\n",
    "for index, cat in enumerate(categories):\n",
    "    for i, row in filtered_data.iterrows():\n",
    "        if row['Score'] == int(cat):\n",
    "            cat_tweets[index].append([row['Id'],row['Score'],row['Text']])\n",
    "    print(len(cat_tweets[index]))\n",
    "#use the smallest number as split criterion: \n",
    "#3500 as total for each category, then split them into 2500 (approx. 70%) and 1000 as trainning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "for cat in range(len(cat_tweets)):\n",
    "    train_set = train_set + cat_tweets[cat][:2500]\n",
    "    test_set = test_set + cat_tweets[cat][2500:3500]\n",
    "    \n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lib_v2.tok(train_set)\n",
    "test_data = lib_v2.tok(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib_v2.show_tweets(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib_v2.show_tweets(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Precision:  67.31301939058172\n",
      "Recall:  24.3\n",
      "F1:  35.70903747244673\n",
      "\n",
      "2\n",
      "Precision:  30.971128608923884\n",
      "Recall:  59.0\n",
      "F1:  40.61962134251291\n",
      "\n",
      "3\n",
      "Precision:  25.979772439949432\n",
      "Recall:  41.1\n",
      "F1:  31.835786212238574\n",
      "\n",
      "4\n",
      "Precision:  33.601841196777904\n",
      "Recall:  29.2\n",
      "F1:  31.24665596575709\n",
      "\n",
      "5\n",
      "Precision:  69.6113074204947\n",
      "Recall:  19.7\n",
      "F1:  30.70927513639906\n",
      "\n",
      "Average F1:  34.024075225870874\n"
     ]
    }
   ],
   "source": [
    "prior_probs, token_probs = lib_v2.learn_nb(train_data)\n",
    "predictions = [(tweet, lib_v2.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_data]\n",
    "lib_v2.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Precision:  74.29352780309937\n",
      "Recall:  32.6\n",
      "F1:  45.31554072838476\n",
      "\n",
      "2\n",
      "Precision:  36.05080831408776\n",
      "Recall:  62.44\n",
      "F1:  45.710102489019036\n",
      "\n",
      "3\n",
      "Precision:  36.51188501934771\n",
      "Recall:  52.84\n",
      "F1:  43.18404707420726\n",
      "\n",
      "4\n",
      "Precision:  48.69179600886918\n",
      "Recall:  43.92\n",
      "F1:  46.18296529968455\n",
      "\n",
      "5\n",
      "Precision:  79.33333333333333\n",
      "Recall:  38.08\n",
      "F1:  51.45945945945945\n",
      "\n",
      "Average F1:  46.370423010151015\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [(tweet, lib_v2.classify_nb(tweet, prior_probs, token_probs)) for tweet in train_data]\n",
    "lib_v2.evaluate(predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815</td>\n",
       "      <td>1181</td>\n",
       "      <td>397</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>1561</td>\n",
       "      <td>679</td>\n",
       "      <td>111</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>783</td>\n",
       "      <td>1321</td>\n",
       "      <td>298</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>421</td>\n",
       "      <td>765</td>\n",
       "      <td>1098</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>384</td>\n",
       "      <td>456</td>\n",
       "      <td>670</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lib_v2.show_confusion_matrix(predictions_train) #unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288</td>\n",
       "      <td>1574</td>\n",
       "      <td>481</td>\n",
       "      <td>113</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375</td>\n",
       "      <td>377</td>\n",
       "      <td>1480</td>\n",
       "      <td>251</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>1328</td>\n",
       "      <td>382</td>\n",
       "      <td>684</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>518</td>\n",
       "      <td>1247</td>\n",
       "      <td>344</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72</td>\n",
       "      <td>441</td>\n",
       "      <td>464</td>\n",
       "      <td>1369</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lib_v2.show_confusion_matrix(predictions_train) #bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can categorize the score into good reviews and bad reviews base on the scores, 1,2 as distatisfied and 4,5 as satisified. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
